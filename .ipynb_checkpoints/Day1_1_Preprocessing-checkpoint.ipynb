{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <br><br><span style=\"color:rebeccapurple\">Overview of machine learning</span>\n",
    "\n",
    "Two most common types of machine learning\n",
    "\n",
    "1. Supervised learning\n",
    " - Data are labelled, i.e., input-output pairs\n",
    " - Goal: making \"good\" predictions\n",
    " - Obvious error metric/loss function where we can compare predictions with observations\n",
    " - EXAMPLE MODELS: linear regression (continuous output), logistic regression (discrete output), decision tree (classification and regression)\n",
    " - EXAMPLE PROBLEMS: classify type of flowers based on physical features like petal width, length and color\n",
    "\n",
    "\n",
    "2. Unsupervised learning\n",
    " - Data are not labelled, i.e., no output\n",
    " - Goal: finding interesting pattern/knowledge discovery\n",
    " - No obvious error metric\n",
    " - EXAMPLE MODELS: clustering, PCA, etc.\n",
    " - EXAMPLE PROBLEMS: identify groups of households that are similar to each other and create targeted marketing\n",
    " \n",
    "Two main types of models\n",
    "\n",
    "1. Parametric models\n",
    " - Make strong assumptions about data (normally distributed, etc.)\n",
    " - Learn and use fixed number of parameters\n",
    " - Example: linear regression model\n",
    " \n",
    " \n",
    "2. Nonparametric models\n",
    " - Make fewer assumptions about data (no asummed distribution)\n",
    " - Learn and use a flexible number of parameters\n",
    " - Example: decision tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <br><br><span style=\"color:rebeccapurple\">Overview of the 3-day workshop</span>\n",
    "\n",
    "1. Preprocessing data and building Machine Learning pipelines in scikit-learn\n",
    "2. Supervised learning with parametric models\n",
    "3. Cross-validation\n",
    "4. Supervised learning with nonparametric models\n",
    "5. Unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <br><br><span style=\"color:rebeccapurple\">Preprocessing</span>\n",
    "\n",
    "Raw data can take on any range of values. By preprocessing data, we make it easier to interpret and use.\n",
    "\n",
    "There are many ways to preproccess data for ML, depending on the modeling purpose and data characteristics.\n",
    "<br><br>We're going to discuss several methods to deal with these three types of data:\n",
    "- Numerical\n",
    "- Categorical\n",
    "- Missing\n",
    "\n",
    "<br>We won't have time to cover every possible way of preprocessing data but let's review what some of your  options are. In a few minutes, we will be learning how to combine your preproccessing steps into a Scikit-learn tool called Pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <br><span style=\"color:purple\"> Overview of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>angle</th>\n",
       "      <th>chord_len</th>\n",
       "      <th>velocity</th>\n",
       "      <th>thickness</th>\n",
       "      <th>sound_pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>126.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   frequency  angle  chord_len  velocity  thickness  sound_pressure\n",
       "0      800.0    0.0     0.3048      71.3   0.002663         126.201\n",
       "1     1000.0    0.0     0.3048      71.3   0.002663         125.201\n",
       "2     1250.0    0.0     0.3048      71.3   0.002663         125.951\n",
       "3     1600.0    0.0     0.3048      71.3   0.002663         127.591\n",
       "4     2000.0    0.0     0.3048      71.3   0.002663         127.461"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import data\n",
    "df = pd.read_csv('datasets/airfoil_self_noise.csv')\n",
    "labels = df.columns\n",
    "## Take a peak at the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common type of data in machine learning is tabular data as shown above. We will work with tabular data throughout this workshop. \n",
    "\n",
    "In tabular data, we have\n",
    "- columns: contain data of a single type. We refer to the type of data in each column as a feature/attribute. \n",
    "- rows: contain a set of observations. We refer to each row as a sample/instance.\n",
    "\n",
    "In (supervised) machine learning, we also have\n",
    "- predictors: the input data of the algorithm or the independent variables in statistical perspective\n",
    "- response/target: the output of the algorithm or the dependent variables in statistical perspective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <br><span style=\"color:purple\"> Numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>angle</th>\n",
       "      <th>chord_len</th>\n",
       "      <th>velocity</th>\n",
       "      <th>thickness</th>\n",
       "      <th>sound_pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1503.000000</td>\n",
       "      <td>1503.000000</td>\n",
       "      <td>1503.000000</td>\n",
       "      <td>1503.000000</td>\n",
       "      <td>1503.000000</td>\n",
       "      <td>1503.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2886.380572</td>\n",
       "      <td>6.782302</td>\n",
       "      <td>0.136548</td>\n",
       "      <td>50.860745</td>\n",
       "      <td>0.011140</td>\n",
       "      <td>124.835943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3152.573137</td>\n",
       "      <td>5.918128</td>\n",
       "      <td>0.093541</td>\n",
       "      <td>15.572784</td>\n",
       "      <td>0.013150</td>\n",
       "      <td>6.898657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>31.700000</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>103.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>800.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.050800</td>\n",
       "      <td>39.600000</td>\n",
       "      <td>0.002535</td>\n",
       "      <td>120.191000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>0.101600</td>\n",
       "      <td>39.600000</td>\n",
       "      <td>0.004957</td>\n",
       "      <td>125.721000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4000.000000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>0.228600</td>\n",
       "      <td>71.300000</td>\n",
       "      <td>0.015576</td>\n",
       "      <td>129.995500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>22.200000</td>\n",
       "      <td>0.304800</td>\n",
       "      <td>71.300000</td>\n",
       "      <td>0.058411</td>\n",
       "      <td>140.987000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          frequency        angle    chord_len     velocity    thickness  \\\n",
       "count   1503.000000  1503.000000  1503.000000  1503.000000  1503.000000   \n",
       "mean    2886.380572     6.782302     0.136548    50.860745     0.011140   \n",
       "std     3152.573137     5.918128     0.093541    15.572784     0.013150   \n",
       "min      200.000000     0.000000     0.025400    31.700000     0.000401   \n",
       "25%      800.000000     2.000000     0.050800    39.600000     0.002535   \n",
       "50%     1600.000000     5.400000     0.101600    39.600000     0.004957   \n",
       "75%     4000.000000     9.900000     0.228600    71.300000     0.015576   \n",
       "max    20000.000000    22.200000     0.304800    71.300000     0.058411   \n",
       "\n",
       "       sound_pressure  \n",
       "count     1503.000000  \n",
       "mean       124.835943  \n",
       "std          6.898657  \n",
       "min        103.380000  \n",
       "25%        120.191000  \n",
       "50%        125.721000  \n",
       "75%        129.995500  \n",
       "max        140.987000  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get a summary of the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <br><span style=\"color:teal\"> Standardization\n",
    "\n",
    "This is the process of converting data into the standard format where each feature has zero mean and unit variance (i.e., std=1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <br><span style=\"color:teal\"> Scaling features to a range\n",
    "\n",
    "Apart from standardization, we can scale features to lie between a given minimum and maximum value, often between zero and one. Range compression helps with robustness due to small standard deviations of features after scaling and at the same time preserves zero entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <br><span style=\"color:teal\"> Normalization\n",
    "\n",
    "This is the process of scaling individual samples to have unit norm. So far, we have scaled data by features i.e., calculations are applied on individual columns. Sometimes, we need to scale data across rows. For example, clustering requires normalization to calculate cosine similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <br><span style=\"color:purple\"> Categorical data\n",
    "Data sometimes come in non-numeric values in predictors and/or response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>age</th>\n",
       "      <th>tumor-size</th>\n",
       "      <th>deg_malig</th>\n",
       "      <th>side</th>\n",
       "      <th>quad</th>\n",
       "      <th>irradiat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>30-39</td>\n",
       "      <td>30-34</td>\n",
       "      <td>3</td>\n",
       "      <td>left</td>\n",
       "      <td>left_low</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>40-49</td>\n",
       "      <td>20-24</td>\n",
       "      <td>2</td>\n",
       "      <td>right</td>\n",
       "      <td>right_up</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>40-49</td>\n",
       "      <td>20-24</td>\n",
       "      <td>2</td>\n",
       "      <td>left</td>\n",
       "      <td>left_low</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>60-69</td>\n",
       "      <td>15-19</td>\n",
       "      <td>2</td>\n",
       "      <td>right</td>\n",
       "      <td>left_up</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>40-49</td>\n",
       "      <td>0-4</td>\n",
       "      <td>2</td>\n",
       "      <td>right</td>\n",
       "      <td>right_low</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 target    age tumor-size  deg_malig   side       quad  \\\n",
       "0  no-recurrence-events  30-39      30-34          3   left   left_low   \n",
       "1  no-recurrence-events  40-49      20-24          2  right   right_up   \n",
       "2  no-recurrence-events  40-49      20-24          2   left   left_low   \n",
       "3  no-recurrence-events  60-69      15-19          2  right    left_up   \n",
       "4  no-recurrence-events  40-49        0-4          2  right  right_low   \n",
       "\n",
       "  irradiat  \n",
       "0       no  \n",
       "1       no  \n",
       "2       no  \n",
       "3       no  \n",
       "4       no  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/breast_cancer.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <br><span style=\"color:blue\"> Question:\n",
    "Which features (age, tumor-size, deg_malig, side, quad, irradiat) are categorical? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <br><span style=\"color:teal\"> Ordinal encoding \n",
    "\n",
    "This is the process of assigning each unique category an integer value. Doing this, we impose a natural ordered relationship between each category.\n",
    "    \n",
    "For example, age is ordered in nature and we can map the different ranges to integer values. More specifically, 30-39 => 0, 40-49 =>1, 50-59 => 2, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <br><span style=\"color:teal\"> One-hot encoding\n",
    "\n",
    "When there is no natural ordinal relationship among different categories, OrdinalEncoder is not an appropriate approach.\n",
    "\n",
    "In addition, when the response variable has no ordinal relationship, encoding its labels as ordered integer values can result in poor performance. For example, suppose we encode the response's labels as 0, 1, 2. The algorithm can return a prediction of 1.5.\n",
    "  \n",
    "One-hot encoding is the process of transforming each label of the orginal categorical variable into a new binary variable. This means the total number of features will increase after preprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <br><span style=\"color:blue\"> Question:\n",
    "    \n",
    "Which features should be processed using one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <br><span style=\"color:teal\"> Label encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn has a separate module to encode target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <br><span style=\"color:teal\"> Imputation of missing values\n",
    "    \n",
    "Sometimes, your data will have missing values (NaN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  target\n",
       "0           5.1          3.5           1.4          0.2       0\n",
       "1           4.9          3.0           1.4          0.2       0\n",
       "2           4.7          3.2           1.3          0.2       0\n",
       "3           4.6          3.1           1.5          0.2       0\n",
       "4           5.0          NaN           1.4          0.2       0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/iris_numeric.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we use the dataset with transformed target labels here. If we apply sklearn transformer on the entire dataset and there are non-numeric values, Python will raise an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check if there is any missing value in the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 781,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check which columns contain missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length    False\n",
       "sepal_width      True\n",
       "petal_length     True\n",
       "petal_width     False\n",
       "target          False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 782,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   149 non-null    float64\n",
      " 2   petal_length  149 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   target        150 non-null    int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 6.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the specific rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal_length  sepal_width  petal_length  petal_width  target\n",
       "4            5.0          NaN           1.4          0.2       0\n",
       "10           5.4          3.7           NaN          0.2       0"
      ]
     },
     "execution_count": 783,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several approaches to imputing missing values before building an estimator. We will explore the most simple approach which involves replacing the missing values with\n",
    "- constant values\n",
    "- statistics like mean, median, mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <br><span style=\"color:purple\"> Additional materials\n",
    "    \n",
    "If you want to see in details how each of these methods alters your data, you can check out the practice below after class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <br><span style=\"color:purple\"> Numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Import data\n",
    "# df = pd.read_csv('datasets/airfoil_self_noise.csv')\n",
    "# labels = df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <br><span style=\"color:teal\"> Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean and std to be used for later scaling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler().fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(scaler.mean_)\n",
    "# print(scaler.scale_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform standardization by centering and scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_array_scaled = scaler.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two methods above can be combined using the fit_transform method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_array_scaled = StandardScaler().fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_scaled = pd.DataFrame(my_array_scaled, columns = labels)\n",
    "# df_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to disable either centering or scaling by either passing with_mean=False or with_std=False to the constructor of StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_array_scaled = StandardScaler(with_mean=False).fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_scaled = pd.DataFrame(my_array_scaled, columns = labels)\n",
    "# df_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Center the data in my_array to mean 0 but disable scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_array_scaled ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_scaled = pd.DataFrame(my_array_scaled, columns = labels)\n",
    "#df_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <br><span style=\"color:teal\"> Scaling features to a range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Apply the transform method to scale the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_array_scaled = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_scaled = pd.DataFrame(my_array_scaled, columns = labels)\n",
    "#df_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <br><span style=\"color:teal\"> Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the transform method to scale the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_array_scaled = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <br><span style=\"color:purple\"> Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('datasets/breast_cancer.csv')\n",
    "# df_transformed = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <br><span style=\"color:teal\"> Ordinal encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fit the data to the encoder to get the labels and corresponding values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc_age = OrdinalEncoder().fit(df[[\"age\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc_age.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OrdinalEncoder module automatically sorts the labels in the feature and assigns the numerical value from 0 to (n-1) with n being the number of unique labels. \n",
    "\n",
    "After fitting the data, we can transform the categorical values in age to numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_transformed[\"age\"] = enc_age.transform(df[[\"age\"]])\n",
    "# df_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode tumor-size variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit the data to get labels\n",
    "# enc_size = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Transform the values and assign the new values to the column tumor-size\n",
    "# df_transformed[\"tumor-size\"] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode irradiat variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <br><span style=\"color:teal\"> One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc_side = OneHotEncoder().fit(df[[\"side\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc_side.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# side_transformed = enc_side.transform(df[[\"side\"]])\n",
    "# type(side_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results from OneHotEncoder are saved as scipy sparse matrix format. We can obtain the actual values using the toarray() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_transformed[enc_side.categories_[0]] = side_transformed.toarray()\n",
    "# df_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode quad variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc_quad = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <br><span style=\"color:teal\"> Label encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('datasets/iris.csv')\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn has a separate module to encode target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le = LabelEncoder().fit(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_transformed = le.transform(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <br><span style=\"color:teal\"> Imputation of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('datasets/iris_numeric.csv')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <br><span style=\"color:teal\"> Using a constant value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imp_const = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0.).fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_transformed_const = pd.DataFrame(imp_const, columns=df.columns)\n",
    "# df_transformed_const.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_transformed_const.loc[[4,10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <br><span style=\"color:teal\"> Using a statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean').fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_transformed_mean = pd.DataFrame(imp_mean, columns=df.columns)\n",
    "# df_transformed_mean.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_transformed_mean.loc[[4,10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
